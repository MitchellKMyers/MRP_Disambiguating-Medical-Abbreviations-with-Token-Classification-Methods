{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from operator import itemgetter\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "import seaborn as sns"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# CRF Tests"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn_crfsuite\n",
    "from sklearn_crfsuite import scorers,CRF\n",
    "from sklearn_crfsuite.metrics import flat_classification_report\n",
    "from sklearn_crfsuite import metrics\n",
    "from nltk.stem import WordNetLemmatizer\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "lemmatizer = WordNetLemmatizer()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "umn_df_ner = pd.read_parquet('umn_df_for_CRFner_40_0725.parquet')\n",
    "medal_df_ner = pd.read_parquet('medal_df_for_CRFner_40_0725.parquet')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "df_wNER = umn_df_ner.copy()\n",
    "#df_wNER = medal_df_ner.copy()\n",
    "all_abvs_list = df_wNER.ABV_final.explode().unique()\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Feature creation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "def word2features(sent, i):\n",
    "    word = sent[i]\n",
    "\n",
    "    features = {\n",
    "        'word.lower()': word.lower(),\n",
    "        'word[-3:]': word[-3:],\n",
    "        'word[-2:]': word[-2:],\n",
    "        'word.isupper()': word.isupper(),\n",
    "        'word.istitle()': word.istitle(),\n",
    "        'word.isdigit()': word.isdigit(),\n",
    "        'word.isABV()': word in all_abvs_list,\n",
    "        'word.lemmatize()': lemmatizer.lemmatize(word),\n",
    "        'word.length()': len(word)\n",
    "        }\n",
    "\n",
    " \n",
    "    if i > 0:\n",
    "        word1 = sent[i-1]\n",
    "        features.update({\n",
    "            '-1:word.lower()': word1.lower(),\n",
    "            '-1:word.istitle()': word1.istitle(),\n",
    "            '-1:word.isupper()': word1.isupper(),\n",
    "        })\n",
    "    else:\n",
    "        features['BOS'] = True\n",
    "\n",
    "    if i < len(sent)-1:\n",
    "        word1 = sent[i+1]\n",
    "\n",
    "        features.update({\n",
    "            '+1:word.lower()': word1.lower(),\n",
    "            '+1:word.istitle()': word1.istitle(),\n",
    "            '+1:word.isupper()': word1.isupper(),\n",
    "        })\n",
    "    else:\n",
    "        features['EOS'] = True\n",
    "\n",
    "    return features\n",
    "\n",
    "\n",
    "def sent2features(sent):\n",
    "    return [word2features(sent, i) for i in range(len(sent))]\n",
    "\n",
    "def sent2labels(sent):\n",
    "    return [label for label in sent]\n",
    "    \n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = np.array([sent2features(s) for s in df_wNER['TEXT_clean_nostp']])\n",
    "y = np.array(df_wNER['NER_labels_words'].values)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,random_state=1)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_test,y_test, test_size=0.3, random_state=1) \n",
    "\n",
    "X_train.shape, X_test.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "((4732,), (828,))"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "crf = sklearn_crfsuite.CRF(\n",
    "    algorithm='lbfgs',\n",
    "    c1=0.1,\n",
    "    c2=0.1,\n",
    "    max_iterations=100,\n",
    "    all_possible_transitions=False,\n",
    "    max_linesearch=100,\n",
    "    verbose=True,  \n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "crf.fit(X_train,y_train)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "loading training data to CRFsuite: 100%|██████████| 4732/4732 [00:01<00:00, 2818.05it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Feature generation\n",
      "type: CRF1d\n",
      "feature.minfreq: 0.000000\n",
      "feature.possible_states: 0\n",
      "feature.possible_transitions: 0\n",
      "0....1....2....3....4....5....6....7....8....9....10\n",
      "Number of features: 56389\n",
      "Seconds required: 0.427\n",
      "\n",
      "L-BFGS optimization\n",
      "c1: 0.100000\n",
      "c2: 0.100000\n",
      "num_memories: 6\n",
      "max_iterations: 100\n",
      "epsilon: 0.000010\n",
      "stop: 10\n",
      "delta: 0.000010\n",
      "linesearch: MoreThuente\n",
      "linesearch.max_iterations: 100\n",
      "\n",
      "Iter 1   time=1.01  loss=106823.56 active=56283 feature_norm=1.00\n",
      "Iter 2   time=0.52  loss=90692.12 active=55896 feature_norm=1.13\n",
      "Iter 3   time=0.54  loss=68072.03 active=55450 feature_norm=1.45\n",
      "Iter 4   time=0.52  loss=59644.62 active=38165 feature_norm=1.70\n",
      "Iter 5   time=0.52  loss=54399.34 active=31688 feature_norm=1.95\n",
      "Iter 6   time=0.52  loss=47390.31 active=28310 feature_norm=2.27\n",
      "Iter 7   time=0.52  loss=29188.75 active=23059 feature_norm=4.20\n",
      "Iter 8   time=0.52  loss=24353.05 active=22978 feature_norm=4.58\n",
      "Iter 9   time=0.53  loss=18509.61 active=21691 feature_norm=6.05\n",
      "Iter 10  time=0.57  loss=12665.12 active=18145 feature_norm=8.45\n",
      "Iter 11  time=0.56  loss=8240.88  active=16040 feature_norm=12.09\n",
      "Iter 12  time=0.52  loss=6446.87  active=13754 feature_norm=14.14\n",
      "Iter 13  time=0.52  loss=5485.48  active=12035 feature_norm=15.23\n",
      "Iter 14  time=0.56  loss=4969.80  active=10849 feature_norm=16.01\n",
      "Iter 15  time=0.53  loss=4600.65  active=10279 feature_norm=16.64\n",
      "Iter 16  time=0.51  loss=4274.70  active=9455  feature_norm=17.88\n",
      "Iter 17  time=0.51  loss=4004.69  active=8938  feature_norm=19.52\n",
      "Iter 18  time=0.51  loss=3724.46  active=8582  feature_norm=20.55\n",
      "Iter 19  time=0.51  loss=3510.56  active=8150  feature_norm=21.66\n",
      "Iter 20  time=0.51  loss=3339.58  active=7633  feature_norm=23.59\n",
      "Iter 21  time=0.52  loss=3103.66  active=7399  feature_norm=25.41\n",
      "Iter 22  time=0.51  loss=2905.24  active=7171  feature_norm=27.45\n",
      "Iter 23  time=0.52  loss=2719.15  active=7033  feature_norm=29.15\n",
      "Iter 24  time=0.52  loss=2585.81  active=6816  feature_norm=31.04\n",
      "Iter 25  time=0.51  loss=2461.51  active=6659  feature_norm=33.02\n",
      "Iter 26  time=0.52  loss=2346.43  active=6459  feature_norm=34.68\n",
      "Iter 27  time=0.52  loss=2247.85  active=6289  feature_norm=36.72\n",
      "Iter 28  time=0.51  loss=2146.28  active=6091  feature_norm=38.72\n",
      "Iter 29  time=0.52  loss=2037.72  active=5893  feature_norm=41.51\n",
      "Iter 30  time=0.52  loss=1931.08  active=5703  feature_norm=44.26\n",
      "Iter 31  time=0.51  loss=1843.80  active=5524  feature_norm=47.29\n",
      "Iter 32  time=0.52  loss=1766.60  active=5374  feature_norm=49.46\n",
      "Iter 33  time=0.51  loss=1673.34  active=5225  feature_norm=52.89\n",
      "Iter 34  time=0.51  loss=1610.49  active=5108  feature_norm=55.20\n",
      "Iter 35  time=0.51  loss=1565.33  active=4956  feature_norm=57.30\n",
      "Iter 36  time=0.51  loss=1524.15  active=4818  feature_norm=58.49\n",
      "Iter 37  time=0.51  loss=1500.23  active=4688  feature_norm=59.12\n",
      "Iter 38  time=0.52  loss=1473.48  active=4480  feature_norm=60.41\n",
      "Iter 39  time=1.02  loss=1462.86  active=4427  feature_norm=60.53\n",
      "Iter 40  time=0.52  loss=1456.25  active=4398  feature_norm=60.59\n",
      "Iter 41  time=0.51  loss=1446.54  active=4265  feature_norm=60.96\n",
      "Iter 42  time=0.51  loss=1440.29  active=4131  feature_norm=61.24\n",
      "Iter 43  time=0.52  loss=1434.03  active=4013  feature_norm=61.49\n",
      "Iter 44  time=0.52  loss=1429.14  active=3947  feature_norm=61.80\n",
      "Iter 45  time=1.03  loss=1426.99  active=3825  feature_norm=62.02\n",
      "Iter 46  time=0.51  loss=1421.86  active=3689  feature_norm=62.11\n",
      "Iter 47  time=0.51  loss=1419.17  active=3513  feature_norm=62.17\n",
      "Iter 48  time=0.51  loss=1415.71  active=3409  feature_norm=62.35\n",
      "Iter 49  time=0.52  loss=1413.14  active=3405  feature_norm=62.29\n",
      "Iter 50  time=0.52  loss=1411.41  active=3393  feature_norm=62.26\n",
      "Iter 51  time=0.52  loss=1409.01  active=3324  feature_norm=62.27\n",
      "Iter 52  time=0.51  loss=1407.29  active=3282  feature_norm=62.26\n",
      "Iter 53  time=0.51  loss=1405.71  active=3242  feature_norm=62.25\n",
      "Iter 54  time=0.52  loss=1404.31  active=3193  feature_norm=62.27\n",
      "Iter 55  time=0.51  loss=1403.93  active=3140  feature_norm=62.27\n",
      "Iter 56  time=0.51  loss=1402.12  active=3135  feature_norm=62.26\n",
      "Iter 57  time=0.51  loss=1401.70  active=3113  feature_norm=62.25\n",
      "Iter 58  time=0.52  loss=1400.73  active=3106  feature_norm=62.23\n",
      "Iter 59  time=0.52  loss=1399.82  active=3102  feature_norm=62.21\n",
      "Iter 60  time=0.52  loss=1399.59  active=3098  feature_norm=62.20\n",
      "Iter 61  time=0.52  loss=1398.44  active=3093  feature_norm=62.20\n",
      "Iter 62  time=0.52  loss=1397.93  active=3088  feature_norm=62.17\n",
      "Iter 63  time=0.53  loss=1397.22  active=3083  feature_norm=62.16\n",
      "Iter 64  time=0.52  loss=1396.74  active=3083  feature_norm=62.13\n",
      "Iter 65  time=0.52  loss=1396.08  active=3082  feature_norm=62.11\n",
      "Iter 66  time=0.52  loss=1395.78  active=3074  feature_norm=62.08\n",
      "Iter 67  time=0.52  loss=1395.08  active=3071  feature_norm=62.06\n",
      "Iter 68  time=0.51  loss=1394.87  active=3080  feature_norm=62.03\n",
      "Iter 69  time=0.52  loss=1394.23  active=3079  feature_norm=62.02\n",
      "Iter 70  time=0.52  loss=1394.02  active=3079  feature_norm=61.99\n",
      "Iter 71  time=0.53  loss=1393.49  active=3080  feature_norm=61.97\n",
      "Iter 72  time=0.52  loss=1393.34  active=3082  feature_norm=61.93\n",
      "Iter 73  time=0.51  loss=1393.01  active=3086  feature_norm=61.91\n",
      "Iter 74  time=0.52  loss=1392.81  active=3084  feature_norm=61.88\n",
      "Iter 75  time=0.51  loss=1392.32  active=3085  feature_norm=61.87\n",
      "Iter 76  time=0.51  loss=1392.21  active=3082  feature_norm=61.84\n",
      "Iter 77  time=0.51  loss=1391.78  active=3084  feature_norm=61.82\n",
      "Iter 78  time=0.52  loss=1391.71  active=3075  feature_norm=61.80\n",
      "Iter 79  time=0.53  loss=1391.36  active=3076  feature_norm=61.78\n",
      "Iter 80  time=0.55  loss=1391.27  active=3074  feature_norm=61.77\n",
      "Iter 81  time=0.57  loss=1390.94  active=3073  feature_norm=61.75\n",
      "Iter 82  time=0.57  loss=1390.92  active=3066  feature_norm=61.73\n",
      "Iter 83  time=0.52  loss=1390.50  active=3067  feature_norm=61.72\n",
      "Iter 84  time=0.52  loss=1390.43  active=3067  feature_norm=61.70\n",
      "Iter 85  time=0.53  loss=1390.09  active=3065  feature_norm=61.69\n",
      "Iter 86  time=1.02  loss=1389.90  active=3069  feature_norm=61.69\n",
      "Iter 87  time=0.51  loss=1389.66  active=3065  feature_norm=61.67\n",
      "Iter 88  time=0.52  loss=1389.46  active=3064  feature_norm=61.65\n",
      "Iter 89  time=0.55  loss=1389.10  active=3066  feature_norm=61.62\n",
      "Iter 90  time=0.52  loss=1389.08  active=3064  feature_norm=61.60\n",
      "Iter 91  time=0.52  loss=1388.28  active=3069  feature_norm=61.58\n",
      "Iter 92  time=0.52  loss=1388.02  active=3065  feature_norm=61.56\n",
      "Iter 93  time=0.52  loss=1387.62  active=3063  feature_norm=61.55\n",
      "Iter 94  time=0.52  loss=1387.35  active=3066  feature_norm=61.54\n",
      "Iter 95  time=0.53  loss=1387.17  active=3063  feature_norm=61.53\n",
      "Iter 96  time=0.54  loss=1386.96  active=3065  feature_norm=61.52\n",
      "Iter 97  time=0.56  loss=1386.78  active=3064  feature_norm=61.51\n",
      "Iter 98  time=0.52  loss=1386.49  active=3058  feature_norm=61.49\n",
      "Iter 99  time=0.52  loss=1386.46  active=3057  feature_norm=61.48\n",
      "Iter 100 time=0.54  loss=1386.09  active=3051  feature_norm=61.47\n",
      "L-BFGS terminated with the maximum number of iterations\n",
      "Total seconds required for training: 54.160\n",
      "\n",
      "Storing the model\n",
      "Number of active features: 3051 (56389)\n",
      "Number of active attributes: 1765 (52148)\n",
      "Number of active labels: 41 (41)\n",
      "Writing labels\n",
      "Writing attributes\n",
      "Writing feature references for transitions\n",
      "Writing feature references for attributes\n",
      "Seconds required: 0.008\n",
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/base.py:197: FutureWarning: From version 0.24, get_params will raise an AttributeError if a parameter cannot be retrieved as an instance attribute. Previously it would return None.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "CRF(algorithm='lbfgs', all_possible_states=None, all_possible_transitions=False,\n",
       "    averaging=None, c=None, c1=0.1, c2=0.1, calibration_candidates=None,\n",
       "    calibration_eta=None, calibration_max_trials=None, calibration_rate=None,\n",
       "    calibration_samples=None, delta=None, epsilon=None, error_sensitive=None,\n",
       "    gamma=None, keep_tempfiles=None, linesearch=None, max_iterations=100,\n",
       "    max_linesearch=100, min_freq=None, model_filename=None, num_memories=None,\n",
       "    pa_type=None, period=None, trainer_cls=None, variance=None, verbose=True)"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "pred = crf.predict(X_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "true_labels = [list(x) for x in y_test]\n",
    "true_predictions = pred"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from seqeval.metrics import f1_score as seq_f1\n",
    "from seqeval.metrics import precision_score, recall_score, classification_report\n",
    "\n",
    "\n",
    "f1_actual = np.round(seq_f1(true_labels, true_predictions, average='macro', scheme='token' ) * 100, 2 )\n",
    "pre_actual = np.round(precision_score(true_labels, true_predictions, average='macro', scheme='token' ) * 100, 2 )\n",
    "rec_actual = np.round(recall_score(true_labels, true_predictions, average='macro', scheme='token' ) * 100, 2 )"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "f1_actual, pre_actual, rec_actual "
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(75.92, 81.45, 75.44)"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "class_report = classification_report(true_labels, true_predictions, output_dict=True )\n",
    "\n",
    "f1s = []\n",
    "precs = []\n",
    "recs = []\n",
    "weights = []\n",
    "\n",
    "for lab in class_report:\n",
    "  if lab not in ['micro avg', 'macro avg','weighted avg', 'A_word']:\n",
    "    f1s.append(class_report[lab]['f1-score'])\n",
    "    precs.append(class_report[lab]['precision'])\n",
    "    recs.append(class_report[lab]['recall'])\n",
    "    weights.append(class_report[lab]['support'])\n",
    "\n",
    "np.average(f1s, weights=weights), np.average(precs, weights=weights), np.average(recs, weights=weights)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# BiLSTM Tests"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "df_ner = pd.read_parquet('medal_df_max500v2_for_ner_1005_0726.parquet')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "#if MeDAL:\n",
    "#df_ner['TEXT_clean_nostp'] = df_ner['TEXT_clean_nostp'].apply(lambda row: [word.lower() for word in row])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "vocab = df_ner.TEXT_clean_nostp.explode().unique()\n",
    "vocab = np.append(vocab, 'ENDPAD')\n",
    "print(vocab)\n",
    "unique_tags = df_ner.NER_labels_words.explode().unique()\n",
    "unique_tags = np.append(unique_tags, 'ENDPAD')\n",
    "print(len(unique_tags))\n",
    "word2idx = {w: i for i, w in enumerate(vocab)}\n",
    "tag2idx = {t: i for i, t in enumerate(unique_tags)}\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['reduced' 'coenzyme' 'qcytochrome' ... 'origamilike' 'normalnormal'\n",
      " 'ENDPAD']\n",
      "1007\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "max_len = 115\n",
    "\n",
    "data = [[word2idx[w] for w in x] for x in df_ner['TEXT_clean_nostp']]\n",
    "data = pad_sequences(data, maxlen=max_len, padding='post', value=word2idx['ENDPAD'])\n",
    "\n",
    "tags = [[tag2idx[w] for w in x] for x in df_ner['NER_labels_words']]\n",
    "tags = pad_sequences(tags, maxlen=max_len, padding='post', value=tag2idx['ENDPAD'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, tags, test_size=0.2,random_state=1)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_test,y_test, test_size=0.3, random_state=1) \n",
    "\n",
    "X_train.shape, X_test.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "((58556, 115), (10248, 115))"
      ]
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#model foundation from: https://colab.research.google.com/drive/1mnz-P30CLxrxQ0yyqpcLwVJgi7e59shi?usp=sharing\n",
    "\n",
    "from keras.models import Model, Input, Sequential\n",
    "from keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "in_dim = len(vocab)\n",
    "in_len = max_len\n",
    "n_tags = len(unique_tags)\n",
    "\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Embedding(input_dim=in_dim, output_dim=256, input_length=in_len))\n",
    "\n",
    "model.add(Dropout(0.3))\n",
    "# Add BiLSTM\n",
    "model.add(Bidirectional(LSTM(units=256, return_sequences=True), merge_mode = 'concat'))\n",
    "\n",
    "model.add(Dropout(0.3))\n",
    "model.add(LSTM(units=128, return_sequences=True))\n",
    "\n",
    "# Add timeDistributed Layer\n",
    "model.add(TimeDistributed(Dense(n_tags, activation=\"softmax\")))\n",
    "\n",
    "#Optimiser \n",
    "adam = Adam(lr=0.005)\n",
    "\n",
    "# Compile model\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    "\n",
    "\n",
    "model.summary()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Set class weights"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#change class weights\n",
    "class_weights = {i:100 for i in range(n_tags)}\n",
    "class_weights[0] = 1\n",
    "class_weights[n_tags-1] = 0\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "history = model.fit(X_train, y_train, batch_size=64, epochs=30, validation_data=(X_val, y_val), class_weight=class_weights)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "source": [
    "from seqeval.metrics import f1_score as seq_f1\n",
    "from seqeval.metrics import precision_score, recall_score, classification_report\n",
    "\n",
    "\n",
    "def get_metrics(preds,labels):\n",
    "    true_predictions = [\n",
    "    [list(tag2idx.keys())[p] for (p, l) in zip(prediction, label) if l != 1006]\n",
    "    for prediction, label in zip(preds, labels)\n",
    "    ]\n",
    "    true_labels = [\n",
    "        [list(tag2idx.keys())[l] for (p, l) in zip(prediction, label) if l != 1006]\n",
    "        for prediction, label in zip(preds, labels)\n",
    "    ]\n",
    "\n",
    "    f1_actual = np.round(seq_f1(true_labels, true_predictions, average='macro', scheme='token' ) * 100, 2 )\n",
    "    pre_actual = np.round(precision_score(true_labels, true_predictions, average='macro', scheme='token' ) * 100, 2 )\n",
    "    rec_actual = np.round(recall_score(true_labels, true_predictions, average='macro', scheme='token' ) * 100, 2 )\n",
    "\n",
    "    print('Macro Performance (F1, Precision, Recall):\\t', f1_actual, pre_actual, rec_actual)\n",
    "\n",
    "    class_report = classification_report(true_labels, true_predictions, output_dict=True )\n",
    "\n",
    "    f1s = []\n",
    "    precs = []\n",
    "    recs = []\n",
    "    weights = []\n",
    "\n",
    "    for lab in class_report:\n",
    "        if lab not in ['micro avg', 'macro avg','weighted avg', 'A_word']:\n",
    "            f1s.append(class_report[lab]['f1-score'])\n",
    "            precs.append(class_report[lab]['precision'])\n",
    "            recs.append(class_report[lab]['recall'])\n",
    "            weights.append(class_report[lab]['support'])\n",
    "\n",
    "    print('Weighted Performance (F1, Precision, Recall):\\t', (np.average(f1s, weights=weights), np.average(precs, weights=weights), np.average(recs, weights=weights)))\n",
    "\n",
    "    true_predictions = []\n",
    "    true_labels = []\n",
    "\n",
    "    for prediction, label in zip(preds, labels):\n",
    "        preds = []\n",
    "        labs = []\n",
    "        for (p, l) in zip(prediction, label):\n",
    "            if l != tag2idx['ENDPAD']:\n",
    "                if p > 0:\n",
    "                    preds.append('ABV')\n",
    "                elif p == 0:\n",
    "                    preds.append('word')\n",
    "\n",
    "                if l > 0:\n",
    "                    labs.append('ABV')\n",
    "                elif l == 0:\n",
    "                    labs.append('word')\n",
    "        true_predictions.append(preds)\n",
    "        true_labels.append(labs)\n",
    "\n",
    "    f1_actual = np.round(seq_f1(true_labels, true_predictions, average=None, scheme='token' ) * 100, 2 )\n",
    "    pre_actual = np.round(precision_score(true_labels, true_predictions, average=None, scheme='token' ) * 100, 2 )\n",
    "    rec_actual = np.round(recall_score(true_labels, true_predictions, average=None, scheme='token' ) * 100, 2 )\n",
    "\n",
    "    print('ABV Identification Performance (F1, Precision, Recall):\\t', f1_actual, pre_actual, rec_actual)\n"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.7.6",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.6 64-bit (conda)"
  },
  "interpreter": {
   "hash": "dca0ade3e726a953b501b15e8e990130d2b7799f14cfd9f4271676035ebe5511"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}